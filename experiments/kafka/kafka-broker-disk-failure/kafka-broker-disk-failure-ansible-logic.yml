---
- hosts: localhost
  connection: local

  vars:
    c_experiment: "kafka-broker-disk-failure"
    c_duration: "{{ lookup('env','TOTAL_CHAOS_DURATION') }}"
    cloud_platform: "{{ lookup('env','CLOUD_PLATFORM') }}"
    disk_name: "{{ lookup('env','DISK_NAME') }}"
    project_id: "{{ lookup('env','PROJECT_ID') }}"
    zone_name: "{{ lookup('env','ZONE_NAME') }}"
    kafka_ns: "{{ lookup('env','KAFKA_NAMESPACE') }}"
    kafka_label: "{{ lookup('env','KAFKA_LABEL') }}"
    kafka_kind: "{{ lookup('env','KAFKA_KIND') }}"
    kafka_instance: "{{ lookup('env','KAFKA_INSTANCE_NAME') }}"
    kafka_broker: "{{ lookup('env','KAFKA_BROKER') }}"
    kafka_stream: "{{ lookup('env','KAFKA_LIVENESS_STREAM') }}"
    kafka_liveness_image: "{{ lookup('env','KAFKA_LIVENESS_IMAGE') }}" 
    kafka_consumer_timeout: "{{ lookup('env','KAFKA_CONSUMER_TIMEOUT') }}" 
    kafka_service: "{{ lookup('env','KAFKA_SERVICE') }}"
    kafka_port: "{{ lookup('env','KAFKA_PORT') }}" 
    kafka_replication_factor: "{{ lookup('env','KAFKA_REPLICATION_FACTOR') }}" 
    zk_ns: "{{ lookup('env','ZOOKEEPER_NAMESPACE') }}"
    zk_label: "{{ lookup('env','ZOOKEEPER_LABEL') }}"
    zk_service: "{{ lookup('env','ZOOKEEPER_SERVICE') }}"
    zk_port: "{{ lookup('env','ZOOKEEPER_PORT') }}" 
    c_engine: "{{ lookup('env','CHAOSENGINE') }}"
    chaos_pod_name: "{{ lookup('env','POD_NAME') }}"
    chaos_uid: "{{ lookup('env','CHAOS_UID') }}"
    c_ns: "{{ lookup('env','CHAOS_NAMESPACE') }}"

  tasks:
    - block:

        - include: kafka-broker-disk-failure-ansible-prerequisites.yml 
      
        - name: "[PreReq]: Including the chaos util for the {{ c_experiment }} experiment"
          include_vars:
            file: /tmp/chaosutil.yml

        ## GENERATE EXP RESULT NAME
        - name: "[PreReq]: Constructing the chaos result name"
          set_fact:
            c_result: "{{ c_engine }}-{{ c_experiment }}"
          when: "c_engine is defined and c_engine != ''"

        ## RECORD START-OF-EXPERIMENT IN LITMUSCHAOS RESULT CR
        - name: "[PreReq]: Updating the chaos result of {{ c_experiment }} experiment (SOT)"
          include_tasks: /utils/runtime/update_chaos_result_resource.yml
          vars:
            status: 'SOT'
            namespace: "{{ c_ns }}"

         ## DISPLAY APP INFORMATION 
        - name: "[Info]: Display the application information passed via the test job"
          debug: 
            msg: 
              - "The application info is as follows:"
              - "Kafka Namespace    : {{ kafka_ns }}"
              - "Kafka Label        : {{ kafka_label }}"

        - name: "[Verify]: Verify the presence of mandatory Kafka broker and disk information"
          debug:
            msg: "kafka-broker-pod: {{ kafka_broker }}; kafka-broker-disk: {{ disk_name }}" 
          failed_when: (kafka_broker is not defined or not kafka_broker) or (disk_name is not defined or not disk_name)  

        ## PERFORM GCLOUD PLATFORM CONFIGURATION STEPS
        - name: "[Authentication]: Perform gcloud authentication"
          include_tasks: "/utils/cloud/gcp/gcloud_configure.yml"
          when: "cloud_platform == 'GKE'"

        ## PRE-CHAOS APPLICATION LIVENESS CHECK
        - name: "[Status]: Verify that the Kafka cluster is healthy"
          include_tasks: "/utils/apps/kafka/kafka_cluster_health.yml"
          vars:     
            delay: 2
            retries: 90

        ## RECORD EVENT FOR PRE-CHAOS CHECK
        - name: "[Event]: Generating an Event for PreChaosCheck"
          include_tasks: /utils/common/generate-kubernetes-chaos-events.yml
        vars:
          stage: "PreChaosCheck"
          exp_pod_name: "{{ chaos_pod_name }}"
          engine_ns: "{{ c_ns }}"
          message: "AUT is Running successfully"
        when: "c_engine is defined and c_engine != ''"

        - name: "[Prepare]: Derive the kafka-broker node name"
          shell: 
            kubectl get pod {{ kafka_broker }} -n {{ kafka_ns }} --no-headers -o custom-columns=:spec.nodeName
          args:
            executable: /bin/bash
          register: node

        - set_fact:
            node_name: "{{ node.stdout }}"

        - name: "[Verification]: Verify that the specified disk is connected to node(pre-chaos)"
          include_tasks: "/utils/cloud/gcp/status_disk.yml"
          when: "cloud_platform == 'GKE'"

        - debug: 
            msg: "specified disk is attached to node"   
          when: "inuse is defined and inuse == true"

        - fail:
            msg: "specified disk not attached to node"
          when: "inuse is defined and inuse == false"   
 
        ## SETUP KAFKA CHAOS INFRA (LIVENESS CLIENT)
       
        - include_tasks: "/utils/apps/kafka/kafka_liveness_stream.yml"
          when: kafka_stream is defined and kafka_stream != '' 

        ## FAULT INJECTION 

        - include_tasks: "{{ c_util }}"
          
        ## POST-CHAOS APPLICATION LIVENESS CHECK

        ## NOTE: This is disabled at present as the recovery post re-attach (in case of mounted disks) 
        ## is still manual
        
        #- name: Verify that the Kafka cluster is healthy
        #  include_tasks: "/utils/apps/kafka/kafka_cluster_health.yml"
        #  vars:     
        #    delay: 1
        #    retries: 60

        ## CHECK FOR KAFKA LIVENESS & CLEANUP

        - block: 

            - name: "[Status]: Verify that the Kafka liveness pod (pub-sub) is uninterrupted"
              include_tasks: "/utils/common/status_app_pod.yml"
              vars: 
                app_ns: "{{ kafka_ns }}"
                app_label: "name=kafka-liveness" 
                delay: 2
                retries: 90

            ## RECORD EVENT FOR POST-CHAOS CHECK
            - name: "[Event]: Generating an Event for PostChaosCheck"
              include_tasks: /utils/common/generate-kubernetes-chaos-events.yml
              vars:
                stage: "PostChaosCheck"
                exp_pod_name: "{{ chaos_pod_name }}"
                engine_ns: "{{ c_ns }}"
                message: "Disk has been reattached and AUT is Running successfully"
              when: "c_engine is defined and c_engine != ''"

            - include_tasks: "/utils/apps/kafka/kafka_liveness_cleanup.yml"

          when: kafka_stream is defined and kafka_stream != ''

        ## POST-CHAOS DISK LIVENESS CHECK

        - name: "[Verification]: Verify that the disk is connected to node (post-chaos)"
          include_tasks: "/utils/cloud/gcp/status_disk.yml"
          when: "cloud_platform == 'GKE'" 

        - debug: 
            msg: "specified disk is attached to node"   
          when: "inuse is defined and inuse == true"

        - fail:
            msg: "specified disk not re-attached to kafka-broker node"
          when: "inuse is defined and inuse == false"   

        - set_fact:
            flag: "Pass"

        - name: "[Result]: Getting the final result of {{ c_experiment }} experiment"
          debug:
            msg: "{{ c_experiment }} experiment has been {{ flag }}ed"

      rescue: 
        - set_fact: 
            flag: "Fail"

        - name: "[Result]: Getting the final result of {{ c_experiment }} experiment"
          debug:
            msg: "{{ c_experiment }} experiment has been {{ flag }}ed"

        - name: "[CleanUP]: Cleanup kafka liveness pods if present"
          include_tasks: "/utils/apps/kafka/kafka_liveness_cleanup.yml"
          ignore_errors: true

      always: 
      
        ## Getting failure step from experiment-pod
        - include_tasks: /utils/runtime/getting_failure_step.yml  
 
        ## RECORD END-OF-TEST IN LITMUSCHAOS RESULT CR
        - name: "[The End]: Updating the chaos result of {{ c_experiment }} experiment (EOT)"
          include_tasks: /utils/runtime/update_chaos_result_resource.yml
          vars:
            status: 'EOT'
            namespace: "{{ c_ns }}"
